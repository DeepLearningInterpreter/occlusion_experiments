{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model evaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JnaC-s_3jaG6",
        "0XyPrArYK5F_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningInterpreter/occlusion_experiments/blob/master/colab_notebooks/training_and_evaluation/model_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vtui76m8NgAL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "This notebook can be used to evaluate the performance of trained detection models on the validation and the test set. "
      ]
    },
    {
      "metadata": {
        "id": "iBLb49moMRRr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is advisable to save the *events* files this notebook outputs, so that they can be accessed later through TensorBoard. For information about storing and loading external data with colab see: https://colab.research.google.com/notebooks/io.ipynb.  \n",
        "\n",
        "Set the variables below as you desire. Choose one of the trained models from the directory:  \"occlusion_experiments\\main_content\\multitude_of_possible_detectors\\training\". "
      ]
    },
    {
      "metadata": {
        "id": "jzOaESVJ2V8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Choose the name of the model\n",
        "MODEL_NAME = \"FRCNN_ext_lr3\"\n",
        "#Choose on which set to evaluate performance \"validation\" or \"test\"\n",
        "SET = \"validation\"\n",
        "\n",
        "#The resulting event files will be saved in the MODEL_DIR\n",
        "MODEL_DIR=\"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/detections/\" + MODEL_NAME\n",
        "#This variable points to the location of the pipeline_config file\n",
        "PIPELINE_CONFIG=\"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/\" + MODEL_NAME + \"/pipeline_\" + SET + \".config\"\n",
        "#This variable points to the directory in which the model checkpoints are saved.\n",
        "CHECKPOINT_DIR=\"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/\" + MODEL_NAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnaC-s_3jaG6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------\n",
        "##Cloning the GitHub repository to the cloud server. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1Gl-A13XLHZc",
        "colab_type": "code",
        "outputId": "0d49a0ae-e173-4a8d-d85b-d6632a4dc02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "cell_type": "code",
      "source": [
        "#Downloading and installing git lfs\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 72 not upgraded.\n",
            "Need to get 4,931 kB of archives.\n",
            "After this operation, 12.3 MB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.6.1 [4,931 kB]\n",
            "Fetched 4,931 kB in 1s (5,196 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 110855 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.6.1_amd64.deb ...\n",
            "Unpacking git-lfs (2.6.1) ...\n",
            "Setting up git-lfs (2.6.1) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Git LFS initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uh3_od2-zxdl",
        "colab_type": "code",
        "outputId": "c1ca31c9-8dfd-4f18-abcd-5b9abef168e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "cell_type": "code",
      "source": [
        "#This may take a while.\n",
        "\n",
        "#Cloning repository. The exclude flag indicates that large files from the \n",
        "#\"frozen_models_for_detection\" subdirectory should not be downloaded\n",
        "!git lfs clone https://github.com/DeepLearningInterpreter/occlusion_experiments.git --exclude=\"occlusion_experiments/main_content/multitude_of_possible_detectors/frozen_models_for_detection\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'occlusion_experiments'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 2182 (delta 126), reused 101 (delta 52), pack-reused 1998\u001b[K\n",
            "Receiving objects: 100% (2182/2182), 185.84 MiB | 1.43 MiB/s, done.\n",
            "Resolving deltas: 100% (403/403), done.\n",
            "Checking out files: 100% (2206/2206), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOvyEGjO0bOT",
        "colab_type": "code",
        "outputId": "dc77b75f-0948-4d90-ed69-236193a3dbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/occlusion_experiments/TF_object_detection_API_modified\")\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/occlusion_experiments/TF_object_detection_API_modified'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "0XyPrArYK5F_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Some installations"
      ]
    },
    {
      "metadata": {
        "id": "LtjUzEd14P91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "os.environ['PYTHONPATH'] += \":/content/occlusion_experiments/TF_object_detection_API_modified/slim\"\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tMLnMQ7bw5M",
        "colab_type": "code",
        "outputId": "5547bff3-47a8-4f1e-be10-c068d27ed763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IuyXOMVE3a8",
        "colab_type": "code",
        "outputId": "75849bf8-229c-4768-8cf3-69fc19a02eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/occlusion_experiments/TF_object_detection_API_modified/object_detection')\n",
        "os.getcwd()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/occlusion_experiments/TF_object_detection_API_modified/object_detection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "4YyBDo2a3Uwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------\n",
        "##Begin Evaluation\n",
        "Running the cell below starts the evaluation. The resulting event files will be stored in the *CHECKPOINT_DIR* directory. The results of the evaluation can be accessed through tensorboard."
      ]
    },
    {
      "metadata": {
        "id": "eBANEdAbwMMu",
        "colab_type": "code",
        "outputId": "bd827b4e-e66a-4afa-bcb8-f7e89f917476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2454
        }
      },
      "cell_type": "code",
      "source": [
        "!python model_main.py \\\n",
        "    --model_dir=$MODEL_DIR \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG \\\n",
        "    --checkpoint_dir=$CHECKPOINT_DIR \\\n",
        "    --run_once=True \n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0125 09:33:29.403961 140443149395840 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0125 09:33:29.404224 140443149395840 tf_logging.py:115] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0125 09:33:29.404406 140443149395840 tf_logging.py:115] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0125 09:33:29.404546 140443149395840 tf_logging.py:115] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0125 09:33:29.404689 140443149395840 tf_logging.py:115] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0125 09:33:29.404817 140443149395840 tf_logging.py:115] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0125 09:33:29.405418 140443149395840 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0125 09:33:29.405580 140443149395840 tf_logging.py:115] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/occlusion_experiments/main_content/multitude_of_possible_detectors/detections/FRCNN_ext_lr3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbb0d35f588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0125 09:33:29.406133 140443149395840 tf_logging.py:115] Using config: {'_model_dir': '/content/occlusion_experiments/main_content/multitude_of_possible_detectors/detections/FRCNN_ext_lr3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbb0d35f588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fbb0d36a400>) includes params argument, but params are not passed to Estimator.\n",
            "W0125 09:33:29.406443 140443149395840 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fbb0d36a400>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Writing pipeline config file to /content/occlusion_experiments/main_content/multitude_of_possible_detectors/detections/FRCNN_ext_lr3/pipeline.config\n",
            "I0125 09:33:29.408062 140443149395840 tf_logging.py:115] Writing pipeline config file to /content/occlusion_experiments/main_content/multitude_of_possible_detectors/detections/FRCNN_ext_lr3/pipeline.config\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0125 09:33:29.608483 140443149395840 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0125 09:33:29.794275 140443149395840 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0125 09:33:30.508684 140443149395840 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0125 09:33:30.545181 140443149395840 tf_logging.py:115] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0125 09:33:32.802785 140443149395840 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0125 09:33:32.820857 140443149395840 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0125 09:33:32.821213 140443149395840 tf_logging.py:115] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0125 09:33:34.183945 140443149395840 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0125 09:33:34.192456 140443149395840 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0125 09:33:34.219477 140443149395840 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0125 09:33:35.197760 140443149395840 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0125 09:33:37.415341 140443149395840 tf_logging.py:115] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-01-25-09:33:37\n",
            "I0125 09:33:37.440649 140443149395840 tf_logging.py:115] Starting evaluation at 2019-01-25-09:33:37\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0125 09:33:38.455392 140443149395840 tf_logging.py:115] Graph was finalized.\n",
            "2019-01-25 09:33:38.627725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-25 09:33:38.628155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-25 09:33:38.628191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-25 09:33:39.523629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-25 09:33:39.523697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-25 09:33:39.523718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-25 09:33:39.523989: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-25 09:33:39.524088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n",
            "I0125 09:33:39.528499 140443149395840 tf_logging.py:115] Restoring parameters from /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0125 09:33:40.504839 140443149395840 tf_logging.py:115] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0125 09:33:40.587514 140443149395840 tf_logging.py:115] Done running local_init_op.\n",
            "2019-01-25 09:33:52.582510: W tensorflow/core/lib/png/png_io.cc:87] PNG warning: iCCP: known incorrect sRGB profile\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0125 09:34:59.273878 140441203332864 tf_logging.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0125 09:34:59.274631 140441203332864 tf_logging.py:115] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
            "INFO:tensorflow:Finished evaluation at 2019-01-25-09:35:32\n",
            "I0125 09:35:32.242162 140443149395840 tf_logging.py:115] Finished evaluation at 2019-01-25-09:35:32\n",
            "INFO:tensorflow:Saving dict for global step 50000: DetectionBoxes_Precision/mAP = 0.57338494, DetectionBoxes_Precision/mAP (large) = 0.6023137, DetectionBoxes_Precision/mAP (medium) = 0.28197154, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.76892823, DetectionBoxes_Precision/mAP@.75IOU = 0.63367844, DetectionBoxes_Recall/AR@1 = 0.53945947, DetectionBoxes_Recall/AR@10 = 0.62216216, DetectionBoxes_Recall/AR@100 = 0.62216216, DetectionBoxes_Recall/AR@100 (large) = 0.652071, DetectionBoxes_Recall/AR@100 (medium) = 0.30625, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.22937906, Loss/BoxClassifierLoss/localization_loss = 0.1375284, Loss/RPNLoss/localization_loss = 0.19590358, Loss/RPNLoss/objectness_loss = 0.12719126, Loss/total_loss = 0.6900024, global_step = 50000, learning_rate = 2e-05, loss = 0.6900024\n",
            "I0125 09:35:32.242620 140443149395840 tf_logging.py:115] Saving dict for global step 50000: DetectionBoxes_Precision/mAP = 0.57338494, DetectionBoxes_Precision/mAP (large) = 0.6023137, DetectionBoxes_Precision/mAP (medium) = 0.28197154, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.76892823, DetectionBoxes_Precision/mAP@.75IOU = 0.63367844, DetectionBoxes_Recall/AR@1 = 0.53945947, DetectionBoxes_Recall/AR@10 = 0.62216216, DetectionBoxes_Recall/AR@100 = 0.62216216, DetectionBoxes_Recall/AR@100 (large) = 0.652071, DetectionBoxes_Recall/AR@100 (medium) = 0.30625, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.22937906, Loss/BoxClassifierLoss/localization_loss = 0.1375284, Loss/RPNLoss/localization_loss = 0.19590358, Loss/RPNLoss/objectness_loss = 0.12719126, Loss/total_loss = 0.6900024, global_step = 50000, learning_rate = 2e-05, loss = 0.6900024\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50000: /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n",
            "I0125 09:35:33.813803 140443149395840 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 50000: /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9ZI6qOnR-CJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}