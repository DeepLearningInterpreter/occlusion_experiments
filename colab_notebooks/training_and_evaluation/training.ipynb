{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JnaC-s_3jaG6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningInterpreter/occlusion_experiments/blob/master/colab_notebooks/training_and_evaluation/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "i_mVQGQ4qPPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training a gun detector\n"
      ]
    },
    {
      "metadata": {
        "id": "3DxFlI0bPDha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "With this notebook a gun detector can be trained. \n",
        "\n",
        "It is advisable to save the checkoint (*.ckpt*) files this notebook outputs, so that the training progress will not be lost. For information about storing and loading external data with colab see: https://colab.research.google.com/notebooks/io.ipynb. From the checkpoint files training can be resumed at any time.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CyhiXJ6aqUD8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Choose a Configuration to train"
      ]
    },
    {
      "metadata": {
        "id": "iHCLy6Ttp_lP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the following codeblock it can be specified:\n",
        "\n",
        "*  What the name of the model is you want to train.\n",
        "*  For how many iterations you want to train the model.\n",
        "\n",
        "The name of the model should match the name of the directory in the \"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/\" folder where the \"pipeline.config\" file is stored.\n"
      ]
    },
    {
      "metadata": {
        "id": "O6o7eEa9QEvC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "which_model = \"FRCNN_ext_lr3\" #the name of the model\n",
        "NUM_TRAIN_STEPS = 75000 #the number of desired training iterations\n",
        "\n",
        "PIPELINE_CONFIG=\"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/\" + which_model + \"/pipeline.config\"\n",
        "MODEL_DIR=\"/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/\" + which_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnaC-s_3jaG6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------\n",
        "##Cloning the GitHub repository to the cloud server. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1Gl-A13XLHZc",
        "colab_type": "code",
        "outputId": "c6248bd0-446d-46e5-d58e-d7870843fdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "cell_type": "code",
      "source": [
        "#Downloading and installing git lfs\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 72 not upgraded.\n",
            "Need to get 4,931 kB of archives.\n",
            "After this operation, 12.3 MB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.6.1 [4,931 kB]\n",
            "Fetched 4,931 kB in 1s (3,859 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 110855 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.6.1_amd64.deb ...\n",
            "Unpacking git-lfs (2.6.1) ...\n",
            "Setting up git-lfs (2.6.1) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Git LFS initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uh3_od2-zxdl",
        "colab_type": "code",
        "outputId": "871bc72f-6f0e-488c-f858-5c6b2d9fdd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "cell_type": "code",
      "source": [
        "#This may take a while.\n",
        "\n",
        "#Cloning repository. The exclude flag indicates that large files from the \n",
        "#\"frozen_models for detection\" and \"evaluation_outcomes\" subdirectories should \n",
        "#not be downloaded\n",
        "!git lfs clone https://github.com/DeepLearningInterpreter/occlusion_experiments.git --exclude=\"occlusion_experiments/main_content/multitude_of_possible_detectors/frozen_models_for_detection, occlusion_experiments/main_content/multitude_of_possible_detectors/evaluation_outcomes\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'occlusion_experiments'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/152)   \u001b[K\rremote: Counting objects:   1% (2/152)   \u001b[K\rremote: Counting objects:   2% (4/152)   \u001b[K\rremote: Counting objects:   3% (5/152)   \u001b[K\rremote: Counting objects:   4% (7/152)   \u001b[K\rremote: Counting objects:   5% (8/152)   \u001b[K\rremote: Counting objects:   6% (10/152)   \u001b[K\rremote: Counting objects:   7% (11/152)   \u001b[K\rremote: Counting objects:   8% (13/152)   \u001b[K\rremote: Counting objects:   9% (14/152)   \u001b[K\rremote: Counting objects:  10% (16/152)   \u001b[K\rremote: Counting objects:  11% (17/152)   \u001b[K\rremote: Counting objects:  12% (19/152)   \u001b[K\rremote: Counting objects:  13% (20/152)   \u001b[K\rremote: Counting objects:  14% (22/152)   \u001b[K\rremote: Counting objects:  15% (23/152)   \u001b[K\rremote: Counting objects:  16% (25/152)   \u001b[K\rremote: Counting objects:  17% (26/152)   \u001b[K\rremote: Counting objects:  18% (28/152)   \u001b[K\rremote: Counting objects:  19% (29/152)   \u001b[K\rremote: Counting objects:  20% (31/152)   \u001b[K\rremote: Counting objects:  21% (32/152)   \u001b[K\rremote: Counting objects:  22% (34/152)   \u001b[K\rremote: Counting objects:  23% (35/152)   \u001b[K\rremote: Counting objects:  24% (37/152)   \u001b[K\rremote: Counting objects:  25% (38/152)   \u001b[K\rremote: Counting objects:  26% (40/152)   \u001b[K\rremote: Counting objects:  27% (42/152)   \u001b[K\rremote: Counting objects:  28% (43/152)   \u001b[K\rremote: Counting objects:  29% (45/152)   \u001b[K\rremote: Counting objects:  30% (46/152)   \u001b[K\rremote: Counting objects:  31% (48/152)   \u001b[K\rremote: Counting objects:  32% (49/152)   \u001b[K\rremote: Counting objects:  33% (51/152)   \u001b[K\rremote: Counting objects:  34% (52/152)   \u001b[K\rremote: Counting objects:  35% (54/152)   \u001b[K\rremote: Counting objects:  36% (55/152)   \u001b[K\rremote: Counting objects:  37% (57/152)   \u001b[K\rremote: Counting objects:  38% (58/152)   \u001b[K\rremote: Counting objects:  39% (60/152)   \u001b[K\rremote: Counting objects:  40% (61/152)   \u001b[K\rremote: Counting objects:  41% (63/152)   \u001b[K\rremote: Counting objects:  42% (64/152)   \u001b[K\rremote: Counting objects:  43% (66/152)   \u001b[K\rremote: Counting objects:  44% (67/152)   \u001b[K\rremote: Counting objects:  45% (69/152)   \u001b[K\rremote: Counting objects:  46% (70/152)   \u001b[K\rremote: Counting objects:  47% (72/152)   \u001b[K\rremote: Counting objects:  48% (73/152)   \u001b[K\rremote: Counting objects:  49% (75/152)   \u001b[K\rremote: Counting objects:  50% (76/152)   \u001b[K\rremote: Counting objects:  51% (78/152)   \u001b[K\rremote: Counting objects:  52% (80/152)   \u001b[K\rremote: Counting objects:  53% (81/152)   \u001b[K\rremote: Counting objects:  54% (83/152)   \u001b[K\rremote: Counting objects:  55% (84/152)   \u001b[K\rremote: Counting objects:  56% (86/152)   \u001b[K\rremote: Counting objects:  57% (87/152)   \u001b[K\rremote: Counting objects:  58% (89/152)   \u001b[K\rremote: Counting objects:  59% (90/152)   \u001b[K\rremote: Counting objects:  60% (92/152)   \rremote: Counting objects:  61% (93/152)   \u001b[K\rremote: Counting objects:  62% (95/152)   \u001b[K\rremote: Counting objects:  63% (96/152)   \u001b[K\rremote: Counting objects:  64% (98/152)   \u001b[K\rremote: Counting objects:  65% (99/152)   \u001b[K\rremote: Counting objects:  66% (101/152)   \u001b[K\rremote: Counting objects:  67% (102/152)   \u001b[K\rremote: Counting objects:  68% (104/152)   \u001b[K\rremote: Counting objects:  69% (105/152)   \u001b[K\rremote: Counting objects:  70% (107/152)   \u001b[K\rremote: Counting objects:  71% (108/152)   \u001b[K\rremote: Counting objects:  72% (110/152)   \u001b[K\rremote: Counting objects:  73% (111/152)   \u001b[K\rremote: Counting objects:  74% (113/152)   \u001b[K\rremote: Counting objects:  75% (114/152)   \u001b[K\rremote: Counting objects:  76% (116/152)   \u001b[K\rremote: Counting objects:  77% (118/152)   \u001b[K\rremote: Counting objects:  78% (119/152)   \u001b[K\rremote: Counting objects:  79% (121/152)   \u001b[K\rremote: Counting objects:  80% (122/152)   \u001b[K\rremote: Counting objects:  81% (124/152)   \u001b[K\rremote: Counting objects:  82% (125/152)   \u001b[K\rremote: Counting objects:  83% (127/152)   \u001b[K\rremote: Counting objects:  84% (128/152)   \u001b[K\rremote: Counting objects:  85% (130/152)   \u001b[K\rremote: Counting objects:  86% (131/152)   \u001b[K\rremote: Counting objects:  87% (133/152)   \u001b[K\rremote: Counting objects:  88% (134/152)   \u001b[K\rremote: Counting objects:  89% (136/152)   \u001b[K\rremote: Counting objects:  90% (137/152)   \u001b[K\rremote: Counting objects:  91% (139/152)   \u001b[K\rremote: Counting objects:  92% (140/152)   \u001b[K\rremote: Counting objects:  93% (142/152)   \u001b[K\rremote: Counting objects:  94% (143/152)   \u001b[K\rremote: Counting objects:  95% (145/152)   \u001b[K\rremote: Counting objects:  96% (146/152)   \u001b[K\rremote: Counting objects:  97% (148/152)   \u001b[K\rremote: Counting objects:  98% (149/152)   \u001b[K\rremote: Counting objects:  99% (151/152)   \u001b[K\rremote: Counting objects: 100% (152/152)   \u001b[K\rremote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 2150 (delta 96), reused 97 (delta 48), pack-reused 1998\u001b[K\n",
            "Receiving objects: 100% (2150/2150), 185.83 MiB | 12.72 MiB/s, done.\n",
            "Resolving deltas: 100% (373/373), done.\n",
            "Checking out files: 100% (2204/2204), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOvyEGjO0bOT",
        "colab_type": "code",
        "outputId": "41afe01a-f0ce-4b14-f72b-97f040d5394e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/occlusion_experiments/TF_object_detection_API_modified\")\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/occlusion_experiments/TF_object_detection_API_modified'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "LtjUzEd14P91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "os.environ['PYTHONPATH'] += \":/content/occlusion_experiments/TF_object_detection_API_modified/slim\"\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tMLnMQ7bw5M",
        "colab_type": "code",
        "outputId": "0b88763d-d963-4ac0-d335-22cb9381d03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IuyXOMVE3a8",
        "colab_type": "code",
        "outputId": "4549e93d-3cc9-4c1b-e785-164b1eecf06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/occlusion_experiments/TF_object_detection_API_modified/object_detection')\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/occlusion_experiments/TF_object_detection_API_modified/object_detection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "5p-FQ1xDSmR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------\n",
        "##Training begins\n"
      ]
    },
    {
      "metadata": {
        "id": "ecLNWYcBUblj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model will automatically pick up training from the last saved checkpoint."
      ]
    },
    {
      "metadata": {
        "id": "zyyGc1v-n7RB",
        "colab_type": "code",
        "outputId": "98964387-e8d9-44be-c414-1a77c9fc6222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3363
        }
      },
      "cell_type": "code",
      "source": [
        "!python model_main.py \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG \\\n",
        "    --model_dir=$MODEL_DIR \\\n",
        "    --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --alsologtostderr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0124 16:24:25.342016 139822863603584 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 75000\n",
            "I0124 16:24:25.342341 139822863603584 tf_logging.py:115] Maybe overwriting train_steps: 75000\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0124 16:24:25.342494 139822863603584 tf_logging.py:115] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0124 16:24:25.342635 139822863603584 tf_logging.py:115] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0124 16:24:25.342765 139822863603584 tf_logging.py:115] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0124 16:24:25.342898 139822863603584 tf_logging.py:115] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0124 16:24:25.343552 139822863603584 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0124 16:24:25.343706 139822863603584 tf_logging.py:115] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2aa14ba588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0124 16:24:25.344208 139822863603584 tf_logging.py:115] Using config: {'_model_dir': '/content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2aa14ba588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2aa14c7400>) includes params argument, but params are not passed to Estimator.\n",
            "W0124 16:24:25.344545 139822863603584 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2aa14c7400>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Writing pipeline config file to /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/pipeline.config\n",
            "I0124 16:24:25.346229 139822863603584 tf_logging.py:115] Writing pipeline config file to /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/pipeline.config\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0124 16:24:25.346879 139822863603584 tf_logging.py:115] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0124 16:24:25.347140 139822863603584 tf_logging.py:115] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "I0124 16:24:25.347496 139822863603584 tf_logging.py:115] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0124 16:24:25.549713 139822863603584 tf_logging.py:125] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0124 16:24:25.627140 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0124 16:24:25.819154 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0124 16:24:26.539524 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0124 16:24:26.579952 139822863603584 tf_logging.py:115] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 16:24:29.034053 139822863603584 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 16:24:29.053327 139822863603584 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0124 16:24:29.053653 139822863603584 tf_logging.py:115] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0124 16:24:31.077440 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 16:24:31.087014 139822863603584 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 16:24:31.114546 139822863603584 tf_logging.py:115] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2108: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0124 16:24:31.149759 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2108: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0124 16:24:33.163942 139822863603584 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0124 16:24:38.334260 139822863603584 tf_logging.py:115] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0124 16:24:38.336038 139822863603584 tf_logging.py:115] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0124 16:24:42.181451 139822863603584 tf_logging.py:115] Graph was finalized.\n",
            "2019-01-24 16:24:42.347993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-24 16:24:42.348483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-01-24 16:24:42.348523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-24 16:24:43.272407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-24 16:24:43.272492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-24 16:24:43.272511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-24 16:24:43.272780: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-24 16:24:43.272906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n",
            "I0124 16:24:43.278888 139822863603584 tf_logging.py:115] Restoring parameters from /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt-50000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0124 16:24:45.029901 139822863603584 tf_logging.py:115] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0124 16:24:45.188705 139822863603584 tf_logging.py:115] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 50000 into /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt.\n",
            "I0124 16:24:52.783190 139822863603584 tf_logging.py:115] Saving checkpoints for 50000 into /content/occlusion_experiments/main_content/multitude_of_possible_detectors/training/FRCNN_ext_lr3/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.12093113, step = 50000\n",
            "I0124 16:25:08.189988 139822863603584 tf_logging.py:115] loss = 0.12093113, step = 50000\n",
            "INFO:tensorflow:global_step/sec: 0.268869\n",
            "I0124 16:25:45.382214 139822863603584 tf_logging.py:115] global_step/sec: 0.268869\n",
            "INFO:tensorflow:loss = 0.18980241, step = 50010 (37.193 sec)\n",
            "I0124 16:25:45.382854 139822863603584 tf_logging.py:115] loss = 0.18980241, step = 50010 (37.193 sec)\n",
            "2019-01-24 16:25:53.575916: W tensorflow/core/framework/allocator.cc:122] Allocation of 19872000 exceeds 10% of system memory.\n",
            "2019-01-24 16:25:53.658262: W tensorflow/core/framework/allocator.cc:122] Allocation of 79488000 exceeds 10% of system memory.\n",
            "2019-01-24 16:25:53.738751: W tensorflow/core/framework/allocator.cc:122] Allocation of 79488000 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global_step/sec: 0.713915\n",
            "I0124 16:25:59.389500 139822863603584 tf_logging.py:115] global_step/sec: 0.713915\n",
            "INFO:tensorflow:loss = 0.079709455, step = 50020 (14.007 sec)\n",
            "I0124 16:25:59.390102 139822863603584 tf_logging.py:115] loss = 0.079709455, step = 50020 (14.007 sec)\n",
            "2019-01-24 16:26:13.384779: W tensorflow/core/framework/allocator.cc:122] Allocation of 20160000 exceeds 10% of system memory.\n",
            "2019-01-24 16:26:13.393908: W tensorflow/core/framework/allocator.cc:122] Allocation of 20160000 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global_step/sec: 0.412285\n",
            "I0124 16:26:23.644538 139822863603584 tf_logging.py:115] global_step/sec: 0.412285\n",
            "INFO:tensorflow:loss = 0.31712008, step = 50030 (24.255 sec)\n",
            "I0124 16:26:23.645122 139822863603584 tf_logging.py:115] loss = 0.31712008, step = 50030 (24.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.27039\n",
            "I0124 16:26:31.516136 139822863603584 tf_logging.py:115] global_step/sec: 1.27039\n",
            "INFO:tensorflow:loss = 0.08811066, step = 50040 (7.871 sec)\n",
            "I0124 16:26:31.516617 139822863603584 tf_logging.py:115] loss = 0.08811066, step = 50040 (7.871 sec)\n",
            "Traceback (most recent call last):\n",
            "  File \"model_main.py\", line 118, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 114, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 610, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1241, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1471, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1156, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1240, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1312, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ta1CE6Pjm3G2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "For changing the checkpoint saving frequency and changing the printing frequency adjust the arguments given to the RunConfig object in the model_main.py file. To influence the minimum time between evaluations change the throttle_secs argument passed to tf.estimator.EvalSpec() in the model_lib.py function. For reference check out: https://github.com/tensorflow/models/issues/5139#issuecomment-418963839. "
      ]
    },
    {
      "metadata": {
        "id": "rqMZsbwpUPUo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}